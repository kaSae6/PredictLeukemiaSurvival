{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Logo-gustave-roussy.jpg/1200px-Logo-gustave-roussy.jpg\" alt=\"Logo 1\" width=\"250\"/>\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/3/3f/Qube_Research_%26_Technologies_Logo.svg/1200px-Qube_Research_%26_Technologies_Logo.svg.png\" alt=\"Logo 2\" width=\"200\" style=\"margin-left: 20px;\"/>\n",
    "</p>\n",
    "\n",
    "# Data Challenge : Leukemia Risk Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GOAL OF THE CHALLENGE and WHY IT IS IMPORTANT:*\n",
    "\n",
    "The goal of the challenge is to **predict disease risk for patients with blood cancer**, in the context of specific subtypes of adult myeloid leukemias.\n",
    "\n",
    "The risk is measured through the **overall survival** of patients, i.e. the duration of survival from the diagnosis of the blood cancer to the time of death or last follow-up.\n",
    "\n",
    "Estimating the prognosis of patients is critical for an optimal clinical management. \n",
    "For exemple, patients with low risk-disease will be offered supportive care to improve blood counts and quality of life, while patients with high-risk disease will be considered for hematopoietic stem cell transplantion.\n",
    "\n",
    "The performance metric used in the challenge is the **IPCW-C-Index**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*THE DATASETS*\n",
    "\n",
    "The **training set is made of 3,323 patients**.\n",
    "\n",
    "The **test set is made of 1,193 patients**.\n",
    "\n",
    "For each patient, you have acces to CLINICAL data and MOLECULAR data.\n",
    "\n",
    "The details of the data are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OUTCOME:\n",
    "  * OS_YEARS = Overall survival time in years\n",
    "  * OS_STATUS = 1 (death) , 0 (alive at the last follow-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- CLINICAL DATA, with one line per patient:\n",
    "  \n",
    "  * ID = unique identifier per patient\n",
    "  * CENTER = clinical center\n",
    "  * BM_BLAST = Bone marrow blasts in % (blasts are abnormal blood cells)\n",
    "  * WBC = White Blood Cell count in Giga/L \n",
    "  * ANC = Absolute Neutrophil count in Giga/L\n",
    "  * MONOCYTES = Monocyte count in Giga/L\n",
    "  * HB = Hemoglobin in g/dL\n",
    "  * PLT = Platelets coutn in Giga/L\n",
    "  * CYTOGENETICS = A description of the karyotype observed in the blood cells of the patients, measured by a cytogeneticist. Cytogenetics is the science of chromosomes. A karyotype is performed from the blood tumoral cells. The convention for notation is ISCN (https://en.wikipedia.org/wiki/International_System_for_Human_Cytogenomic_Nomenclature). Cytogenetic notation are: https://en.wikipedia.org/wiki/Cytogenetic_notation. Note that a karyotype can be normal or abnornal. The notation 46,XX denotes a normal karyotype in females (23 pairs of chromosomes including 2 chromosomes X) and 46,XY in males (23 pairs of chromosomes inclusing 1 chromosme X and 1 chromsome Y). A common abnormality in the blood cancerous cells might be for exemple a loss of chromosome 7 (monosomy 7, or -7), which is typically asssociated with higher risk disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- GENE MOLECULAR DATA, with one line per patient per somatic mutation. Mutations are detected from the sequencing of the blood tumoral cells. \n",
    "We call somatic (= acquired) mutations the mutations that are found in the tumoral cells but not in other cells of the body.\n",
    "\n",
    "  * ID = unique identifier per patient\n",
    "  * CHR START END = position of the mutation on the human genome\n",
    "  * REF ALT = reference and alternate (=mutant) nucleotide\n",
    "  * GENE = the affected gene\n",
    "  * PROTEIN_CHANGE = the consequence of the mutation on the protei that is expressed by a given gene\n",
    "  * EFFECT = a broad categorization of the mutation consequences on a given gene.\n",
    "  * VAF = Variant Allele Fraction = it represents the **proportion** of cells with the deleterious mutations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-survival in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.24.1)\n",
      "Requirement already satisfied: ecos in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-survival) (2.0.14)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-survival) (1.5.0)\n",
      "Requirement already satisfied: numexpr in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-survival) (2.10.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-survival) (2.2.5)\n",
      "Requirement already satisfied: osqp<1.0.0,>=0.6.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-survival) (0.6.7.post3)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-survival) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-survival) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<1.7,>=1.6.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-survival) (1.6.1)\n",
      "Requirement already satisfied: qdldl in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from osqp<1.0.0,>=0.6.3->scikit-survival) (0.1.7.post5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn<1.7,>=1.6.1->scikit-survival) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/melissa/Library/Python/3.13/lib/python/site-packages (from pandas>=1.4.0->scikit-survival) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/melissa/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%pip install scikit-survival\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './clinical_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msksurv\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Surv\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Clinical Data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./clinical_train.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m df_eval = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m./clinical_test.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Molecular Data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './clinical_train.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored , concordance_index_ipcw\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sksurv.util import Surv\n",
    "\n",
    "# Clinical Data\n",
    "df = pd.read_csv(\"./clinical_train.csv\")\n",
    "df_eval = pd.read_csv(\"./clinical_test.csv\")\n",
    "\n",
    "# Molecular Data\n",
    "maf_df = pd.read_csv(\"./molecular_train.csv\")\n",
    "maf_eval = pd.read_csv(\"./molecular_test.csv\")\n",
    "\n",
    "target_df = pd.read_csv(\"./target_train.csv\")\n",
    "target_df_test = pd.read_csv(\"./target_test.csv\")\n",
    "\n",
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation (clinical data only)\n",
    "\n",
    "For survival analysis, we’ll format the dataset so that OS_YEARS represents the time variable and OS_STATUS represents the event indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'OS_YEARS' is NaN if conversion caused any issues\n",
    "target_df.dropna(subset=['OS_YEARS', 'OS_STATUS'], inplace=True)\n",
    "\n",
    "# Check the data types to ensure 'OS_STATUS' is boolean and 'OS_YEARS' is numeric\n",
    "print(target_df[['OS_STATUS', 'OS_YEARS']].dtypes)\n",
    "\n",
    "# Contarget_dfvert 'OS_YEARS' to numeric if it isn’t already\n",
    "target_df['OS_YEARS'] = pd.to_numeric(target_df['OS_YEARS'], errors='coerce')\n",
    "\n",
    "# Ensure 'OS_STATUS' is boolean\n",
    "target_df['OS_STATUS'] = target_df['OS_STATUS'].astype(bool)\n",
    "\n",
    "# Select features\n",
    "features = ['BM_BLAST', 'HB', 'PLT']\n",
    "target = ['OS_YEARS', 'OS_STATUS']\n",
    "\n",
    "# Create the survival data format\n",
    "X = df.loc[df['ID'].isin(target_df['ID']), features]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', target_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Splitting the Dataset\n",
    "We’ll split the data into training and testing sets to evaluate the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival-aware imputation for missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train[['BM_BLAST', 'HB', 'PLT']] = imputer.fit_transform(X_train[['BM_BLAST', 'HB', 'PLT']])\n",
    "X_test[['BM_BLAST', 'HB', 'PLT']] = imputer.transform(X_test[['BM_BLAST', 'HB', 'PLT']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Training Standard Machine Learning Methods\n",
    "\n",
    "In this step, we train a standard LightGBM model on survival data, but we do not account for censoring. Instead of treating the event status, we use only the observed survival times as the target variable. This approach disregards whether an individual’s event (e.g., death) was observed or censored, effectively treating the problem as a standard regression task. While this method provides a basic benchmark, it may be less accurate than survival-specific models (but still be explored!), as it does not leverage the information contained in censored observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import lightgbm as lgb\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.util import Surv\n",
    "\n",
    "# Define LightGBM parameters\n",
    "lgbm_params = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Prepare the data for LightGBM\n",
    "# Scale the target (OS_YEARS) to reduce skew, apply weights based on event status\n",
    "X_train_lgb = X_train  # Features for training\n",
    "y_train_transformed = y_train['OS_YEARS']\n",
    "\n",
    "# Create LightGBM dataset\n",
    "train_dataset = lgb.Dataset(X_train_lgb, label=y_train_transformed)\n",
    "\n",
    "# Train the LightGBM model\n",
    "model = lgb.train(params=lgbm_params, train_set=train_dataset)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "pred_train = -model.predict(X_train)\n",
    "pred_test = -model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "train_ci_ipcw = concordance_index_ipcw(y_train, y_train, pred_train, tau=7)[0]\n",
    "test_ci_ipcw = concordance_index_ipcw(y_train, y_test, pred_test, tau=7)[0]\n",
    "print(f\"LightGBM Survival Model Concordance Index IPCW on train: {train_ci_ipcw:.2f}\")\n",
    "print(f\"LightGBM Survival Model Concordance Index IPCW on test: {test_ci_ipcw:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the LightGBM model is defined as `model`\n",
    "plt.figure(figsize=(20, 10))\n",
    "lgb.plot_tree(model, tree_index=0, figsize=(20, 10), show_info=['split_gain', 'internal_value', 'internal_count', 'leaf_count'])\n",
    "plt.title(\"First Tree in LightGBM Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Cox Proportional Hazards Model\n",
    "\n",
    "To account for censoring in survival analysis, we use a Cox Proportional Hazards (Cox PH) model, a widely used method that estimates the effect of covariates on survival times without assuming a specific baseline survival distribution. The Cox PH model is based on the hazard function, $h(t | X)$, which represents the instantaneous risk of an event (e.g., death) at time $t$ given covariates $X$. The model assumes that the hazard can be expressed as:\n",
    "\n",
    "$$h(t | X) = h_0(t) \\exp(\\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p)$$\n",
    "\n",
    "\n",
    "where $h_0(t)$ is the baseline hazard function, and $\\beta$ values are coefficients for each covariate, representing the effect of $X$ on the hazard. Importantly, the proportional hazards assumption implies that the hazard ratios between individuals are constant over time. This approach effectively leverages both observed and censored survival times, making it a more suitable method for survival data compared to standard regression techniques that ignore censoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Cox Proportional Hazards model\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "cox_cindex_train = concordance_index_ipcw(y_train, y_train, cox.predict(X_train), tau=7)[0]\n",
    "cox_cindex_test = concordance_index_ipcw(y_train, y_test, cox.predict(X_test), tau=7)[0]\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on train: {cox_cindex_train:.2f}\")\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on test: {cox_cindex_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Naive Approach to Incorporate Mutations\n",
    "\n",
    "In this step, we take a very naive approach to account for genetic mutations by simply counting the total number of somatic mutations per patient. Instead of analyzing specific mutations or their biological impact, we use this aggregate count as a basic feature to reflect the mutational burden for each individual. Although simplistic, this feature can serve as a general indicator of genetic variability across patients, which may influence survival outcomes. More sophisticated mutation analysis could be incorporated in future models to improve predictive power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step: Extract the number of somatic mutations per patient\n",
    "# Group by 'ID' and count the number of mutations (rows) per patient\n",
    "tmp = maf_df.groupby('ID').size().reset_index(name='Nmut')\n",
    "\n",
    "# Merge with the training dataset and replace missing values in 'Nmut' with 0\n",
    "df_2 = df.merge(tmp, on='ID', how='left').fillna({'Nmut': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "features = ['BM_BLAST', 'HB', 'PLT', 'Nmut']\n",
    "target = ['OS_YEARS', 'OS_STATUS']\n",
    "\n",
    "# Create the survival data format\n",
    "X = df_2.loc[df_2['ID'].isin(target_df['ID']), features]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival-aware imputation for missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train[['BM_BLAST', 'HB', 'PLT', 'Nmut']] = imputer.fit_transform(X_train[['BM_BLAST', 'HB', 'PLT', 'Nmut']])\n",
    "X_test[['BM_BLAST', 'HB', 'PLT', 'Nmut']] = imputer.transform(X_test[['BM_BLAST', 'HB', 'PLT', 'Nmut']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Cox Proportional Hazards model\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "cox_cindex_train = concordance_index_ipcw(y_train, y_train, cox.predict(X_train), tau=7)[0]\n",
    "cox_cindex_test = concordance_index_ipcw(y_train, y_test, cox.predict(X_test), tau=7)[0]\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on train: {cox_cindex_train:.2f}\")\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on test: {cox_cindex_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_eval = maf_eval.groupby('ID').size().reset_index(name='Nmut')\n",
    "\n",
    "# Merge with the training dataset and replace missing values in 'Nmut' with 0\n",
    "df_eval = df_eval.merge(tmp_eval, on='ID', how='left').fillna({'Nmut': 0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval[['BM_BLAST', 'HB', 'PLT', 'Nmut']] = imputer.transform(df_eval[['BM_BLAST', 'HB', 'PLT', 'Nmut']])\n",
    "\n",
    "prediction_on_test_set = cox.predict(df_eval.loc[:, features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series(prediction_on_test_set, index=df_eval['ID'], name='OS_YEARS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission.to_csv('./benchmark_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_submission = pd.Series(np.random.uniform(0, 1, len(submission)),index =submission.index, name='OS_YEARS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_submission.to_csv('./random_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
